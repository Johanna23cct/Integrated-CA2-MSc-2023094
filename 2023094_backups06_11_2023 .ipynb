{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/johanna23cct/integrated-CA2-MSc-2023094.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#git remote add origin https://github.com/johanna23cct/integrated-CA2-MSc-2023094.git\n",
    "#git branch -M main\n",
    "#git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac692706",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install skforecast --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b68e89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modeling and Forecasting\n",
    "# ==============================================================================\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "#from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "# Spark\n",
    "# import SparkSession library \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lower, concat_ws, regexp_replace, split, size, length, broadcast\n",
    "from pyspark.sql.types import DoubleType, StructType, StructField, ArrayType, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# Warnings configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efeff729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22943cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SparkContext \n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc08cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"data_projectTweets\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce48466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to creating a customer dataframe by declaring the schema and passing values, but didn't work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2dc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema = StructType().add(\"Ids\",\"integer\").add(\"Date\",\"string\").add(\"Flag\", \"string\").add(\"User\",'string').add(\"Text\", \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217df978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************************************************\n",
    "# *                                  Start with the Data                                                         *\n",
    "# ****************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee728360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big headache and colapse, to read the dataset\n",
    "# I was load the file from my hadoop (local)\n",
    "# df = spark.read.csv('home/hduser/Documnets/CA2', header+True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02317436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move the dataset fiel to HDFS path from my terminal:\n",
    "#First check:  $fs -ls/user1\n",
    "#Next move :   $hadoop fs-put./ProjectTweets.scv/user1\n",
    "#Check again : $fs -ls/user1\n",
    "#I will use direct from the path, to have one of five V' (Velocity) \n",
    "\n",
    "\n",
    "#folowiong you can see the two way to load the dataset, \n",
    "#    (command)+(file://)+(/path/)+(filename)\n",
    "#I will use direct from the path, to have one of five V' (Velocity) \n",
    "\n",
    "Tweets_path = \"/user1/ProjectTweets.csv\"\n",
    "#df = spark.read.csv(\"file:///home/hduser/Documents/CA2/ProjectTweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819163a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/user1/ProjectTweets.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96717e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark_df = spark.read.csv(\"file:///home/hduser/Documents/CA2/ProjectTweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c2acf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = spark.read.csv(\"/user1/ProjectTweets.csv\", header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c04d9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['_c0', 'Ids', 'Date', 'Flag', 'User', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b21ba804",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, column_name in enumerate(column_names):\n",
    "    spark_df = spark_df.withColumnRenamed(\"_c\" + str(i),column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a85ddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|_c0|       Ids|                Date|    Flag|           User|                Text|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4259eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some excercises, it didn't work to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be6e5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#header = tweets.first()\n",
    "\n",
    "#tweets = tweets.filter(lambda row: row != header) \n",
    "#tweets = tweets.map(lambda row: [int(elem) for elem in row.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd24a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = sc.textFile(\"Tweets_path \")\n",
    "#Header = tweets.first()\n",
    "\n",
    "#tweets = tweets.filter(lambda row: row != header) \n",
    "#tweets = tweets.map(lambda row: [int(elem) for elem in row.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f73e960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the schema for my DataFrame\n",
    "# was one  error because i didn' import pyspark.sql.types as typ\n",
    "# but next did it, the command worked, great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05e8145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fields = [\n",
    "#    *[\n",
    "#        typ.StructField(h[1:-1], typ.IntegerType(), True)\n",
    "#        for h in header.split(',')\n",
    "#    ]\n",
    "#]\n",
    "#schema = typ.StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8977065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First put the Titles to see better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "958e899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_names  = ['_c0','Ids', 'Date', 'Flag', 'User', 'Text']    \n",
    "#full_df = pd.read_csv('file:///home/hduser/Documents/CA2/ProjectTweets.csv', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2db9aba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# display the total number of rows data\n",
    "total_rows = spark_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a17421a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 1,600,000\n"
     ]
    }
   ],
   "source": [
    "formatted_total_rows = \"{:,}\".format(total_rows)\n",
    "print(\"Total Rows:\", formatted_total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "937d6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the file whit  row's title  ******* ******* ****** ******* ****** ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "973e5b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.write.csv(\"file:///home/hduser/Documents/CA2/Title_pro_Tweets.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b74b848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column  ************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "840bac8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_to_drop = ['Flag', 'Unnamed: 0']\n",
    "spark_df = spark_df.drop('Flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19058a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e65c0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+--------------------+\n",
      "|_c0|       Ids|                Date|           User|                Text|\n",
      "+---+----------+--------------------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "933034f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema = StructType().add(\"_c0\",\"integer\").add(\"Ids\",\"integer\").add(\"Date\",\"string\").add(\"Flag\", \"string\").add(\"User\",'string').add(\"Text\", \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70531f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a UDF to apply VADER sentiment analysis to a Text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b38b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(Text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment = sid.polarity_scores(Text)\n",
    "    return sentiment['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a97aafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b98f4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_udf = udf(analyze_sentiment, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "786eb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a43e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"sentiment\", sentiment_udf(spark_df[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3311372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "|_c0|       Ids|                Date|           User|                Text|sentiment|\n",
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|  -0.0173|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|    -0.75|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|   0.4939|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|    -0.25|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|  -0.6597|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|      0.0|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |   0.4767|\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|    0.745|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|      0.0|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|      0.0|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|      0.0|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|      0.0|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|  -0.5994|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|  -0.1027|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|   0.3724|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|   0.4545|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|  -0.9081|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |      0.0|\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|   0.6988|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|      gi_gi_bee|@FakerPattyPattz ...|   0.1779|\n",
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(spark_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68d7fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', 'Ids', 'Date', 'Flag', 'User', 'Text']\n"
     ]
    }
   ],
   "source": [
    "#why i have Flag  again??\n",
    "print(column_names[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10198758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "|_c0|       Ids|                Date|           User|                Text|sentiment|\n",
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|  -0.0173|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|    -0.75|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|   0.4939|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|    -0.25|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|  -0.6597|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|      0.0|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |   0.4767|\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|    0.745|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|      0.0|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|      0.0|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|      0.0|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|      0.0|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|  -0.5994|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|  -0.1027|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|   0.3724|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|   0.4545|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|  -0.9081|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |      0.0|\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|   0.6988|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|      gi_gi_bee|@FakerPattyPattz ...|   0.1779|\n",
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#to show\n",
    "\n",
    "spark_df.drop('Flag').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "769b2036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "|_c0|       Ids|                Date|           User|                Text|sentiment|\n",
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|  -0.0173|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|    -0.75|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|   0.4939|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|    -0.25|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|  -0.6597|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|      0.0|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |   0.4767|\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|    0.745|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|      0.0|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|      0.0|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|      0.0|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|      0.0|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|  -0.5994|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|  -0.1027|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|   0.3724|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|   0.4545|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|  -0.9081|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |      0.0|\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|   0.6988|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|      gi_gi_bee|@FakerPattyPattz ...|   0.1779|\n",
      "+---+----------+--------------------+---------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(spark_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a625ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc43f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating my Dataframe (i did it in line 27 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d79e15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#        Basic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "697f3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Header_df = spark.read.csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5502ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ff684aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"word_count\", size(split(Tweets[\"Text\"], \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec1d7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5312f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial did't work because is a Panda code: TypeError: 'Column' object is not callable\n",
    "\n",
    "#Tweets['word_count'] = Tweets['Text'].apply(lambda x: len(str(x).split(\"\")))\n",
    "#Tweets[['Text','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86e96ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Text|word_count|\n",
      "+--------------------+----------+\n",
      "|@switchfoot http:...|        20|\n",
      "|is upset that he ...|        22|\n",
      "|@Kenichan I dived...|        19|\n",
      "|my whole body fee...|        11|\n",
      "|@nationwideclass ...|        22|\n",
      "|@Kwesidei not the...|         6|\n",
      "|         Need a hug |         4|\n",
      "|@LOLTrish hey  lo...|        24|\n",
      "|@Tatiana_K nope t...|         7|\n",
      "|@twittera que me ...|         6|\n",
      "|spring break in p...|         8|\n",
      "|I just re-pierced...|         6|\n",
      "|@caregiving I cou...|        21|\n",
      "|@octolinz16 It it...|        16|\n",
      "|@smarrison i woul...|        23|\n",
      "|@iamjazzyfizzle I...|        20|\n",
      "|Hollis' death sce...|        19|\n",
      "|about to file taxes |         5|\n",
      "|@LettyA ahh ive a...|        12|\n",
      "|@FakerPattyPattz ...|        13|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\", \"word_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f000ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44bfbfc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tutorial did't work because is a Panda code:TypeError: 'Column' object is not callable\n",
    "#Tweets['char_count'] = Tweets['Text'].str.len()\n",
    "## this also includes spaces\n",
    "#Tweets[['Text','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33b87218",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"char_count\", length(Tweets[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bc221ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Text|char_count|\n",
      "+--------------------+----------+\n",
      "|@switchfoot http:...|       115|\n",
      "|is upset that he ...|       111|\n",
      "|@Kenichan I dived...|        89|\n",
      "|my whole body fee...|        47|\n",
      "|@nationwideclass ...|       111|\n",
      "|@Kwesidei not the...|        29|\n",
      "|         Need a hug |        11|\n",
      "|@LOLTrish hey  lo...|        99|\n",
      "|@Tatiana_K nope t...|        36|\n",
      "|@twittera que me ...|        25|\n",
      "|spring break in p...|        43|\n",
      "|I just re-pierced...|        26|\n",
      "|@caregiving I cou...|        94|\n",
      "|@octolinz16 It it...|        77|\n",
      "|@smarrison i woul...|       117|\n",
      "|@iamjazzyfizzle I...|       103|\n",
      "|Hollis' death sce...|        93|\n",
      "|about to file taxes |        20|\n",
      "|@LettyA ahh ive a...|        64|\n",
      "|@FakerPattyPattz ...|        79|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\", \"char_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2664f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27f18d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", concat_ws(\"\", lower(col(\"Text\"))))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "248ab3b6",
   "metadata": {},
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03d3c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b0ef5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", regexp_replace(col(\"Text\"), r'[^\\w\\s]', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e490786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|switchfoot httptw...|\n",
      "|is upset that he ...|\n",
      "|kenichan i dived ...|\n",
      "|my whole body fee...|\n",
      "|nationwideclass n...|\n",
      "|kwesidei not the ...|\n",
      "|         need a hug |\n",
      "|loltrish hey  lon...|\n",
      "|tatiana_k nope th...|\n",
      "|twittera que me m...|\n",
      "|spring break in p...|\n",
      "|i just repierced ...|\n",
      "|caregiving i coul...|\n",
      "|octolinz16 it it ...|\n",
      "|smarrison i would...|\n",
      "|iamjazzyfizzle i ...|\n",
      "|hollis death scen...|\n",
      "|about to file taxes |\n",
      "|lettya ahh ive al...|\n",
      "|fakerpattypattz o...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd407b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Stop Words\n",
    "#Load stop word once and broadcast it to all worker nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "855bcd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop  = stopwords.words('english')\n",
    "broadcasted_stopwords = spark.sparkContext.broadcast(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ec531d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a funcion to remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7af8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01f47f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "645f2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_udf = udf(remove_stopwords, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db22a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b9af6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", remove_stopwords_udf(Tweets[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd635b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|switchfoot httptw...|\n",
      "|upset cant update...|\n",
      "|kenichan dived ma...|\n",
      "|whole body feels ...|\n",
      "|nationwideclass b...|\n",
      "| kwesidei whole crew|\n",
      "|            need hug|\n",
      "|loltrish hey long...|\n",
      "|tatiana_k nope didnt|\n",
      "|  twittera que muera|\n",
      "|spring break plai...|\n",
      "|      repierced ears|\n",
      "|caregiving couldn...|\n",
      "|octolinz16 counts...|\n",
      "|smarrison wouldve...|\n",
      "|iamjazzyfizzle wi...|\n",
      "|hollis death scen...|\n",
      "|          file taxes|\n",
      "|lettya ahh ive al...|\n",
      "|fakerpattypattz o...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79d38b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************************************************************************\n",
    "#*                                       T O K E N I Z A T I O N                                                 *\n",
    "#*****************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71ef43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77667d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_Tweets(Text):\n",
    "    blob = TextBlob(Text)\n",
    "    return [str(word) for word in blob.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76bf1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_udf = udf(tokenize_Tweets, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b9275b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d1f7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn('tokenized_Tweets', tokenize_udf(spark_df['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95d5b405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+--------------------+---------+--------------------+\n",
      "|_c0|       Ids|                Date|           User|                Text|sentiment|    tokenized_Tweets|\n",
      "+---+----------+--------------------+---------------+--------------------+---------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|  -0.0173|[switchfoot, http...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|    -0.75|[is, upset, that,...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|   0.4939|[Kenichan, I, div...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|    -0.25|[my, whole, body,...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|  -0.6597|[nationwideclass,...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|      0.0|[Kwesidei, not, t...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |   0.4767|      [Need, a, hug]|\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|    0.745|[LOLTrish, hey, l...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|      0.0|[Tatiana_K, nope,...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|      0.0|[twittera, que, m...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|      0.0|[spring, break, i...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|      0.0|[I, just, re-pier...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|  -0.5994|[caregiving, I, c...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|  -0.1027|[octolinz16, It, ...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|   0.3724|[smarrison, i, wo...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|   0.4545|[iamjazzyfizzle, ...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|  -0.9081|[Hollis, death, s...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |      0.0|[about, to, file,...|\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|   0.6988|[LettyA, ahh, ive...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|      gi_gi_bee|@FakerPattyPattz ...|   0.1779|[FakerPattyPattz,...|\n",
      "+---+----------+--------------------+---------------+--------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90246c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************************************************************************\n",
    "#*                                        S T R E M M I N G                                                     *\n",
    "#****************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d6a7c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2fff73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Udf for Stremming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "887e442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    words = nltk.word_tokenize(Text)\n",
    "    stemmer_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b6ff488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ebb79476",
   "metadata": {},
   "outputs": [],
   "source": [
    "strem_udf = udf(stem_text, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "382451d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "113bec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"StemmingExample\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "53fca207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1313bb06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stem_udf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10946/3642991614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTweets_stemmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stemmed_Text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stem_udf' is not defined"
     ]
    }
   ],
   "source": [
    "Tweets_stemmed = spark_df.withColumn(\"Stemmed_Text\", stem_udf(spark_df[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show te resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_stemmed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08e036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382efd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d758ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14644c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Procesising in panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.withColumn(\"Text\", lower(df[\"text\"]))\n",
    "#df = df.withColumn(\"Text\", regexp_replace(df[\"text\"], \"[^a-z0-9\\\\s]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42db868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4de8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1276b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c2580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ff6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680cd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ff69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Text\", lower(df[\"text\"]))\n",
    "df = df.withColumn(\"Text\", regexp_replace(df[\"text\"], \"[^a-z0-9\\\\s]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd8298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
