{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60e3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/johanna23cct/integrated-CA2-MSc-2023094.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0494ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#git remote add origin https://github.com/johanna23cct/integrated-CA2-MSc-2023094.git\n",
    "#git branch -M main\n",
    "#git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac692706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990b285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bokeh in /home/hduser/.local/lib/python3.10/site-packages (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1 in /home/hduser/.local/lib/python3.10/site-packages (from bokeh) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/hduser/.local/lib/python3.10/site-packages (from bokeh) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/hduser/.local/lib/python3.10/site-packages (from bokeh) (2.0.3)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /home/hduser/.local/lib/python3.10/site-packages (from bokeh) (2023.10.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /usr/lib/python3/dist-packages (from bokeh) (6.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/lib/python3/dist-packages (from bokeh) (21.3)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /usr/lib/python3/dist-packages (from bokeh) (3.0.3)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/lib/python3/dist-packages (from bokeh) (5.4.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/lib/python3/dist-packages (from bokeh) (9.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->bokeh) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hduser/.local/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hduser/.local/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96e2bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skforecast in /home/hduser/.local/lib/python3.10/site-packages (0.10.1)\n",
      "Requirement already satisfied: joblib<1.4,>=1.1.0 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (1.3.2)\n",
      "Requirement already satisfied: optuna<3.3,>=2.10.0 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (3.2.0)\n",
      "Requirement already satisfied: numpy<1.26,>=1.20 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (1.24.3)\n",
      "Requirement already satisfied: tqdm<4.66,>=4.57.0 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (4.65.2)\n",
      "Requirement already satisfied: pandas<2.1,>=1.2 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn<1.4,>=1.0 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (1.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/hduser/.local/lib/python3.10/site-packages (from optuna<3.3,>=2.10.0->skforecast) (1.12.0)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in /home/hduser/.local/lib/python3.10/site-packages (from optuna<3.3,>=2.10.0->skforecast) (0.10.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna<3.3,>=2.10.0->skforecast) (5.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/hduser/.local/lib/python3.10/site-packages (from optuna<3.3,>=2.10.0->skforecast) (2.0.22)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from optuna<3.3,>=2.10.0->skforecast) (21.3)\n",
      "Requirement already satisfied: colorlog in /home/hduser/.local/lib/python3.10/site-packages (from optuna<3.3,>=2.10.0->skforecast) (6.7.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hduser/.local/lib/python3.10/site-packages (from pandas<2.1,>=1.2->skforecast) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas<2.1,>=1.2->skforecast) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hduser/.local/lib/python3.10/site-packages (from pandas<2.1,>=1.2->skforecast) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/lib/python3/dist-packages (from scikit-learn<1.4,>=1.0->skforecast) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from scikit-learn<1.4,>=1.0->skforecast) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/hduser/.local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna<3.3,>=2.10.0->skforecast) (4.5.0)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna<3.3,>=2.10.0->skforecast) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<2.1,>=1.2->skforecast) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/hduser/.local/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna<3.3,>=2.10.0->skforecast) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install skforecast --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b68e89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modeling and Forecasting\n",
    "# ==============================================================================\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "#from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "# Spark\n",
    "# import SparkSession library \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lower, concat_ws, regexp_replace, split, size, length, broadcast\n",
    "from pyspark.sql.types import DoubleType, StructType, StructField, ArrayType, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# Warnings configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22943cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SparkContext HOW I CAN SHOW THAT ... SC  It is not working to me, in the first time!\n",
    "# that ok now, I know, is sc.master.  I was put only sc\n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc08cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"data_projectTweets\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce48466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a customer dataframe by declaring the schema and passing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2dc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(\"Ids\",\"integer\").add(\"Date\",\"string\").add(\"Flag\", \"string\").add(\"User\",'string').add(\"Text\", \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217df978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************************************************\n",
    "# *                                  Start with the Data                                                         *\n",
    "# ****************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee728360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big headache and colapse, to read the dataset\n",
    "# I was load the file from my hadoop (local)\n",
    "# df = spark.read.csv('home/hduser/Documnets/CA2', header+True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02317436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folowiong you can see the two way to load the dataset, \n",
    "#    (command)+(file://)+(/path/)+(filename)\n",
    "#I will use direct from the path, to have one of five V' (Velocity) \n",
    "\n",
    "path = \"/user1/ProjectTweets.csv\"\n",
    "#df = spark.read.csv(\"file:///home/hduser/Documents/CA2/ProjectTweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8da8c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data. i can't belive, it is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd24a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets = sc.textFile(\"file:///home/hduser/Documents/CA2/ProjectTweets.csv\")\n",
    "header = tweets.first()\n",
    "\n",
    "tweets = tweets \\\n",
    "    .filter(lambda row: row != header) \\\n",
    "    .map(lambda row: [int(elem) for elem in row.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f73e960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the schema for my DataFrame\n",
    "# was one  error because i didn' import pyspark.sql.types as typ\n",
    "# but next did it, the command worked, great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05e8145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    *[\n",
    "        typ.StructField(h[1:-1], typ.IntegerType(), True)\n",
    "        for h in header.split(',')\n",
    "    ]\n",
    "]\n",
    "schema = typ.StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "958e899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names  = ['_c0','Ids', 'Date', 'Flag', 'User', 'Text']    \n",
    "full_df = pd.read_csv('file:///home/hduser/Documents/CA2/ProjectTweets.csv', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c77733de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>Ids</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flag</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0         Ids                          Date      Flag             User  \\\n",
       "0    0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1    1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2    2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3    3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4    4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                Text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2db9aba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 1,600,000\n"
     ]
    }
   ],
   "source": [
    "# display the total number of rows data\n",
    "total_rows = full_df.shape[0]\n",
    "formatted_total_rows = \"{:,}\".format(total_rows)\n",
    "print(\"Total Rows:\", formatted_total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "937d6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the file whit  row's title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "973e5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17e5c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Header_df = spark.read.csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b74b848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column  *****************************help********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "840bac8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+--------------------+\n",
      "|_c0|       Ids|                Date|           User|                Text|\n",
      "+---+----------+--------------------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 00:47:32,452 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Ids, Date, User, Text\n",
      " Schema: _c0, Ids, Date, User, Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\n"
     ]
    }
   ],
   "source": [
    "#df = full_df.drop(['Flag', 'Unnamed: 0', ], axis=NO_QUERY)\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "Header_df.drop('Flag').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "933034f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(\"_c0\",\"integer\").add(\"Ids\",\"integer\").add(\"Date\",\"string\").add(\"Flag\", \"string\").add(\"User\",'string').add(\"Text\", \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "629db55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70531f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a UDF to apply VADER sentiment analysis to a Text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b38b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(Text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment = sid.polarity_scores(Text)\n",
    "    return sentiment['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a97aafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b98f4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_udf = udf(analyze_sentiment, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "786eb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a43e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Header_df = Header_df.withColumn(\"sentiment\", sentiment_udf(Header_df[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3311372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 00:47:49,297 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Ids, Date, Flag, User, Text\n",
      " Schema: _c0, Ids, Date, Flag, User, Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\n",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+---------+\n",
      "|_c0|       Ids|                Date|    Flag|           User|                Text|sentiment|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+---------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|  -0.0173|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|    -0.75|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|   0.4939|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|    -0.25|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|  -0.6597|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|      0.0|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |   0.4767|\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|    0.745|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|      0.0|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|      0.0|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|      0.0|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|      0.0|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|  -0.5994|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|  -0.1027|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|   0.3724|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|   0.4545|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|  -0.9081|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |      0.0|\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|   0.6988|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|   0.1779|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 00:48:51,714 WARN python.PythonUDFRunner: Detected deadlock while completing task 0.0 in stage 5 (TID 6): Attempting to kill Python Worker\n",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(Header_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68d7fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', 'Ids', 'Date', 'Flag', 'User']\n"
     ]
    }
   ],
   "source": [
    "#why i have Flag  again??\n",
    "print(column_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2da973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 00:51:18,093 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Ids, Date, User, Text\n",
      " Schema: _c0, Ids, Date, User, Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\n",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+--------------------+--------------------+\n",
      "|_c0|       Ids|                Date|           User|                Text|    tokenized_Tweets|\n",
      "+---+----------+--------------------+---------------+--------------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|[switchfoot, http...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|[is, upset, that,...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|[Kenichan, I, div...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|[my, whole, body,...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|[nationwideclass,...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|[Kwesidei, not, t...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |      [Need, a, hug]|\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|[LOLTrish, hey, l...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|[Tatiana_K, nope,...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|[twittera, que, m...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|[spring, break, i...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|[I, just, re-pier...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|[caregiving, I, c...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|[octolinz16, It, ...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|[smarrison, i, wo...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|[iamjazzyfizzle, ...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|[Hollis, death, s...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |[about, to, file,...|\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|[LettyA, ahh, ive...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|      gi_gi_bee|@FakerPattyPattz ...|[FakerPattyPattz,...|\n",
      "+---+----------+--------------------+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#df = full_df.drop(['Flag', 'Unnamed: 0', ], axis=NO_QUERY)\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "Header_df.drop('Flag').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a625ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bc43f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating my Dataframe (i did it in line 27 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d79e15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#        Basic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "697f3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Header_df = spark.read.csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5502ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Header_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ff684aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"word_count\", size(split(Tweets[\"Text\"], \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec1d7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5312f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial did't work because is a Panda code: TypeError: 'Column' object is not callable\n",
    "\n",
    "#Tweets['word_count'] = Tweets['Text'].apply(lambda x: len(str(x).split(\"\")))\n",
    "#Tweets[['Text','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86e96ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Text|word_count|\n",
      "+--------------------+----------+\n",
      "|@switchfoot http:...|        20|\n",
      "|is upset that he ...|        22|\n",
      "|@Kenichan I dived...|        19|\n",
      "|my whole body fee...|        11|\n",
      "|@nationwideclass ...|        22|\n",
      "|@Kwesidei not the...|         6|\n",
      "|         Need a hug |         4|\n",
      "|@LOLTrish hey  lo...|        24|\n",
      "|@Tatiana_K nope t...|         7|\n",
      "|@twittera que me ...|         6|\n",
      "|spring break in p...|         8|\n",
      "|I just re-pierced...|         6|\n",
      "|@caregiving I cou...|        21|\n",
      "|@octolinz16 It it...|        16|\n",
      "|@smarrison i woul...|        23|\n",
      "|@iamjazzyfizzle I...|        20|\n",
      "|Hollis' death sce...|        19|\n",
      "|about to file taxes |         5|\n",
      "|@LettyA ahh ive a...|        12|\n",
      "|@FakerPattyPattz ...|        13|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\", \"word_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f000ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "44bfbfc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tutorial did't work because is a Panda code:TypeError: 'Column' object is not callable\n",
    "#Tweets['char_count'] = Tweets['Text'].str.len()\n",
    "## this also includes spaces\n",
    "#Tweets[['Text','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33b87218",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"char_count\", length(Tweets[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1bc221ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Text|char_count|\n",
      "+--------------------+----------+\n",
      "|@switchfoot http:...|       115|\n",
      "|is upset that he ...|       111|\n",
      "|@Kenichan I dived...|        89|\n",
      "|my whole body fee...|        47|\n",
      "|@nationwideclass ...|       111|\n",
      "|@Kwesidei not the...|        29|\n",
      "|         Need a hug |        11|\n",
      "|@LOLTrish hey  lo...|        99|\n",
      "|@Tatiana_K nope t...|        36|\n",
      "|@twittera que me ...|        25|\n",
      "|spring break in p...|        43|\n",
      "|I just re-pierced...|        26|\n",
      "|@caregiving I cou...|        94|\n",
      "|@octolinz16 It it...|        77|\n",
      "|@smarrison i woul...|       117|\n",
      "|@iamjazzyfizzle I...|       103|\n",
      "|Hollis' death sce...|        93|\n",
      "|about to file taxes |        20|\n",
      "|@LettyA ahh ive a...|        64|\n",
      "|@FakerPattyPattz ...|        79|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\", \"char_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2664f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "27f18d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", concat_ws(\"\", lower(col(\"Text\"))))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "248ab3b6",
   "metadata": {},
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03d3c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b0ef5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", regexp_replace(col(\"Text\"), r'[^\\w\\s]', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e490786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|switchfoot httptw...|\n",
      "|is upset that he ...|\n",
      "|kenichan i dived ...|\n",
      "|my whole body fee...|\n",
      "|nationwideclass n...|\n",
      "|kwesidei not the ...|\n",
      "|         need a hug |\n",
      "|loltrish hey  lon...|\n",
      "|tatiana_k nope th...|\n",
      "|twittera que me m...|\n",
      "|spring break in p...|\n",
      "|i just repierced ...|\n",
      "|caregiving i coul...|\n",
      "|octolinz16 it it ...|\n",
      "|smarrison i would...|\n",
      "|iamjazzyfizzle i ...|\n",
      "|hollis death scen...|\n",
      "|about to file taxes |\n",
      "|lettya ahh ive al...|\n",
      "|fakerpattypattz o...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bd407b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Stop Words\n",
    "#Load stop word once and broadcast it to all worker nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "855bcd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop  = stopwords.words('english')\n",
    "broadcasted_stopwords = spark.sparkContext.broadcast(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5ec531d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a funcion to remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d7af8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "01f47f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "645f2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_udf = udf(remove_stopwords, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "db22a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b9af6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", remove_stopwords_udf(Tweets[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fd635b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|switchfoot httptw...|\n",
      "|upset cant update...|\n",
      "|kenichan dived ma...|\n",
      "|whole body feels ...|\n",
      "|nationwideclass b...|\n",
      "| kwesidei whole crew|\n",
      "|            need hug|\n",
      "|loltrish hey long...|\n",
      "|tatiana_k nope didnt|\n",
      "|  twittera que muera|\n",
      "|spring break plai...|\n",
      "|      repierced ears|\n",
      "|caregiving couldn...|\n",
      "|octolinz16 counts...|\n",
      "|smarrison wouldve...|\n",
      "|iamjazzyfizzle wi...|\n",
      "|hollis death scen...|\n",
      "|          file taxes|\n",
      "|lettya ahh ive al...|\n",
      "|fakerpattypattz o...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 23:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fa691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "79d38b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************************************************************************\n",
    "#*                                       T O K E N I Z A T I O N                                                 *\n",
    "#*****************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a37a081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0b03af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_Tweets(Text):\n",
    "    blob = TextBlob(Text)\n",
    "    return [str(word) for word in blob.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6d46ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_udf = udf(tokenize_Tweets, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "19998a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "acc7a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "Header_df = Header_df.withColumn('tokenized_Tweets', tokenize_udf(Header_df['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "add556c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 00:51:07,744 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Ids, Date, Flag, User, Text\n",
      " Schema: _c0, Ids, Date, Flag, User, Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\n",
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+--------------------+\n",
      "|_c0|       Ids|                Date|    Flag|           User|                Text|    tokenized_Tweets|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|[switchfoot, http...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|[is, upset, that,...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|[Kenichan, I, div...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|[my, whole, body,...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|[nationwideclass,...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|[Kwesidei, not, t...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |      [Need, a, hug]|\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|[LOLTrish, hey, l...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|[Tatiana_K, nope,...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|[twittera, que, m...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|[spring, break, i...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|[I, just, re-pier...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|[caregiving, I, c...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|[octolinz16, It, ...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|[smarrison, i, wo...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|[iamjazzyfizzle, ...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|[Hollis, death, s...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |[about, to, file,...|\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|[LettyA, ahh, ive...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|[FakerPattyPattz,...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Header_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "26f682e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************************************************************************\n",
    "#*                                        S T R E M M I N G                                                     *\n",
    "#****************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2a04a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "acf379c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Udf for Stremming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a5f710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    stemmed_words = [st.stem(word) for word in text.split()]\n",
    "    return \" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ce76a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1ffc8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "strem_udf = udf(stem_text, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "382451d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "00c7a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"StemmingExample\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7573d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "49af24a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stem_udf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6933/2785381495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTweets_stemmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stemmed_Text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stem_udf' is not defined"
     ]
    }
   ],
   "source": [
    "Tweets_stemmed = Tweets.withColumn(\"Stemmed_Text\", stem_udf(Tweets[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show te resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_stemmed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d33b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114167bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d758ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14644c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Procesising in panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.withColumn(\"Text\", lower(df[\"text\"]))\n",
    "#df = df.withColumn(\"Text\", regexp_replace(df[\"text\"], \"[^a-z0-9\\\\s]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42db868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4de8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1276b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c2580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ff6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680cd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ff69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Text\", lower(df[\"text\"]))\n",
    "df = df.withColumn(\"Text\", regexp_replace(df[\"text\"], \"[^a-z0-9\\\\s]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd8298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
