{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60e3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/johanna23cct/integrated-CA2-MSc-2023094.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0494ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#git remote add origin https://github.com/johanna23cct/integrated-CA2-MSc-2023094.git\n",
    "#git branch -M main\n",
    "#git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac692706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990b285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bokeh in /home/hduser/.local/lib/python3.10/site-packages (3.3.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/lib/python3/dist-packages (from bokeh) (5.4.1)\n",
      "Requirement already satisfied: contourpy>=1 in /home/hduser/.local/lib/python3.10/site-packages (from bokeh) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/hduser/.local/lib/python3.10/site-packages (from bokeh) (1.24.3)\n",
      "Requirement already satisfied: tornado>=5.1 in /usr/lib/python3/dist-packages (from bokeh) (6.1)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /usr/lib/python3/dist-packages (from bokeh) (3.0.3)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/lib/python3/dist-packages (from bokeh) (9.0.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/hduser/.local/lib/python3.10/site-packages (from bokeh) (2.0.3)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /home/hduser/.local/lib/python3.10/site-packages (from bokeh) (2023.10.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/lib/python3/dist-packages (from bokeh) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->bokeh) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hduser/.local/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hduser/.local/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96e2bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skforecast in /home/hduser/.local/lib/python3.10/site-packages (0.10.1)\n",
      "Requirement already satisfied: optuna<3.3,>=2.10.0 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (3.2.0)\n",
      "Requirement already satisfied: pandas<2.1,>=1.2 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (2.0.3)\n",
      "Requirement already satisfied: numpy<1.26,>=1.20 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (1.24.3)\n",
      "Requirement already satisfied: tqdm<4.66,>=4.57.0 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (4.65.2)\n",
      "Requirement already satisfied: scikit-learn<1.4,>=1.0 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (1.3.0)\n",
      "Requirement already satisfied: joblib<1.4,>=1.1.0 in /home/hduser/.local/lib/python3.10/site-packages (from skforecast) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from optuna<3.3,>=2.10.0->skforecast) (21.3)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna<3.3,>=2.10.0->skforecast) (5.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/hduser/.local/lib/python3.10/site-packages (from optuna<3.3,>=2.10.0->skforecast) (2.0.22)\n",
      "Requirement already satisfied: colorlog in /home/hduser/.local/lib/python3.10/site-packages (from optuna<3.3,>=2.10.0->skforecast) (6.7.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/hduser/.local/lib/python3.10/site-packages (from optuna<3.3,>=2.10.0->skforecast) (1.12.0)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in /home/hduser/.local/lib/python3.10/site-packages (from optuna<3.3,>=2.10.0->skforecast) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas<2.1,>=1.2->skforecast) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hduser/.local/lib/python3.10/site-packages (from pandas<2.1,>=1.2->skforecast) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hduser/.local/lib/python3.10/site-packages (from pandas<2.1,>=1.2->skforecast) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/lib/python3/dist-packages (from scikit-learn<1.4,>=1.0->skforecast) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from scikit-learn<1.4,>=1.0->skforecast) (3.2.0)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna<3.3,>=2.10.0->skforecast) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/hduser/.local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna<3.3,>=2.10.0->skforecast) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<2.1,>=1.2->skforecast) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/hduser/.local/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna<3.3,>=2.10.0->skforecast) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install skforecast --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b68e89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.dowload()\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modeling and Forecasting\n",
    "# ==============================================================================\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "#from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "# Spark\n",
    "# import SparkSession library \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lower, concat_ws, regexp_replace, split, size, length, broadcast\n",
    "from pyspark.sql.types import DoubleType, StructType, StructField, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# Warnings configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22943cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SparkContext HOW I CAN SHOW THAT ... SC  It is not working to me, in the first time!\n",
    "# that ok now, I know, is sc.master.  I was put only sc\n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8cc08cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"data_projectTweets\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce48466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a customer dataframe by declaring the schema and passing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb2dc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(\"Ids\",\"integer\").add(\"Date\",\"string\").add(\"Flag\", \"string\").add(\"User\",'string').add(\"Text\", \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "217df978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "#                                   Start whit the Data\n",
    "#=========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee728360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big headache and colapse, to read the dataset\n",
    "# I was load the file from my hadoop (local)\n",
    "# df = spark.read.csv('home/hduser/Documnets/CA2', header+True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02317436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folowiong you can see the two way to load the dataset, \n",
    "#    (command)+(file://)+(/path/)+(filename)\n",
    "#I will use direct from the path, to have one of five V' (Velocity) \n",
    "\n",
    "path = \"/user1/ProjectTweets.csv\"\n",
    "#df = spark.read.csv(\"file:///home/hduser/Documents/CA2/ProjectTweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8da8c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data. i can't belive, it is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd24a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets = sc.textFile(\"file:///home/hduser/Documents/CA2/ProjectTweets.csv\")\n",
    "header = tweets.first()\n",
    "\n",
    "tweets = tweets \\\n",
    "    .filter(lambda row: row != header) \\\n",
    "    .map(lambda row: [int(elem) for elem in row.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f73e960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the schema for my DataFrame\n",
    "# was one  error because i didn' import pyspark.sql.types as typ\n",
    "# but next did it, the command worked, great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "05e8145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    *[\n",
    "        typ.StructField(h[1:-1], typ.IntegerType(), True)\n",
    "        for h in header.split(',')\n",
    "    ]\n",
    "]\n",
    "schema = typ.StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "958e899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names  = ['_c0','Ids', 'Date', 'Flag', 'User', 'Text']    \n",
    "full_df = pd.read_csv('file:///home/hduser/Documents/CA2/ProjectTweets.csv', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c77733de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>Ids</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flag</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0         Ids                          Date      Flag             User  \\\n",
       "0    0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1    1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2    2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3    3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4    4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                Text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2db9aba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 1,600,000\n"
     ]
    }
   ],
   "source": [
    "# display the total number of rows data\n",
    "total_rows = full_df.shape[0]\n",
    "formatted_total_rows = \"{:,}\".format(total_rows)\n",
    "print(\"Total Rows:\", formatted_total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "937d6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the file whit  row's title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "973e5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "17e5c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Header_df = spark.read.csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b74b848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "840bac8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+--------------------+\n",
      "|_c0|       Ids|                Date|           User|                Text|\n",
      "+---+----------+--------------------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 02:44:44,839 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Ids, Date, User, Text\n",
      " Schema: _c0, Ids, Date, User, Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\n"
     ]
    }
   ],
   "source": [
    "#df = full_df.drop(['Flag', 'Unnamed: 0', ], axis=NO_QUERY)\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "Header_df.drop('Flag').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "933034f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(\"_c0\",\"integer\").add(\"Ids\",\"integer\").add(\"Date\",\"string\").add(\"Flag\", \"string\").add(\"User\",'string').add(\"Text\", \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c96ce5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70531f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a UDF to apply VADER sentiment analysis to a Text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b38b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(Text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment = sid.polarity_scores(Text)\n",
    "    return sentiment['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a97aafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b98f4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_udf = udf(analyze_sentiment, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "786eb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1a43e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Header_df = Header_df.withColumn(\"sentiment\", sentiment_udf(Header_df[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3311372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 02:44:55,830 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Ids, Date, Flag, User, Text\n",
      " Schema: _c0, Ids, Date, Flag, User, Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\n",
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+---------+\n",
      "|_c0|       Ids|                Date|    Flag|           User|                Text|sentiment|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+---------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|  -0.0173|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|    -0.75|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|   0.4939|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|    -0.25|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|  -0.6597|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|      0.0|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |   0.4767|\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|    0.745|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|      0.0|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|      0.0|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|      0.0|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|      0.0|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|  -0.5994|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|  -0.1027|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|   0.3724|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|   0.4545|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|  -0.9081|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |      0.0|\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|   0.6988|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|   0.1779|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(Header_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "68d7fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', 'Ids', 'Date', 'Flag', 'User']\n"
     ]
    }
   ],
   "source": [
    "#why i have Flag  again??\n",
    "print(column_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a625ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc43f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating my Dataframe (i did it in line 27 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6658293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#        Basic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a0345235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Header_df = spark.read.csv(\"file:///home/hduser/Documents/CA2/Header_Proj_Tweets.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "06f2ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Header_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4b0056bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"word_count\", size(split(Tweets[\"Text\"], \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "864460d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a5312f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial did't work because is a Panda code: TypeError: 'Column' object is not callable\n",
    "\n",
    "#Tweets['word_count'] = Tweets['Text'].apply(lambda x: len(str(x).split(\"\")))\n",
    "#Tweets[['Text','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f9af2e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Text|word_count|\n",
      "+--------------------+----------+\n",
      "|@switchfoot http:...|        20|\n",
      "|is upset that he ...|        22|\n",
      "|@Kenichan I dived...|        19|\n",
      "|my whole body fee...|        11|\n",
      "|@nationwideclass ...|        22|\n",
      "|@Kwesidei not the...|         6|\n",
      "|         Need a hug |         4|\n",
      "|@LOLTrish hey  lo...|        24|\n",
      "|@Tatiana_K nope t...|         7|\n",
      "|@twittera que me ...|         6|\n",
      "|spring break in p...|         8|\n",
      "|I just re-pierced...|         6|\n",
      "|@caregiving I cou...|        21|\n",
      "|@octolinz16 It it...|        16|\n",
      "|@smarrison i woul...|        23|\n",
      "|@iamjazzyfizzle I...|        20|\n",
      "|Hollis' death sce...|        19|\n",
      "|about to file taxes |         5|\n",
      "|@LettyA ahh ive a...|        12|\n",
      "|@FakerPattyPattz ...|        13|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\", \"word_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "285f0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CCharaccters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "44bfbfc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tutorial did't work because is a Panda code:TypeError: 'Column' object is not callable\n",
    "#Tweets['char_count'] = Tweets['Text'].str.len()\n",
    "## this also includes spaces\n",
    "#Tweets[['Text','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "33b87218",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"char_count\", length(Tweets[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1bc221ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Text|char_count|\n",
      "+--------------------+----------+\n",
      "|@switchfoot http:...|       115|\n",
      "|is upset that he ...|       111|\n",
      "|@Kenichan I dived...|        89|\n",
      "|my whole body fee...|        47|\n",
      "|@nationwideclass ...|       111|\n",
      "|@Kwesidei not the...|        29|\n",
      "|         Need a hug |        11|\n",
      "|@LOLTrish hey  lo...|        99|\n",
      "|@Tatiana_K nope t...|        36|\n",
      "|@twittera que me ...|        25|\n",
      "|spring break in p...|        43|\n",
      "|I just re-pierced...|        26|\n",
      "|@caregiving I cou...|        94|\n",
      "|@octolinz16 It it...|        77|\n",
      "|@smarrison i woul...|       117|\n",
      "|@iamjazzyfizzle I...|       103|\n",
      "|Hollis' death sce...|        93|\n",
      "|about to file taxes |        20|\n",
      "|@LettyA ahh ive a...|        64|\n",
      "|@FakerPattyPattz ...|        79|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\", \"char_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f2664f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e5f91db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", concat_ws(\"\", lower(col(\"Text\"))))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe20f164",
   "metadata": {},
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "176a03fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "183cc7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", regexp_replace(col(\"Text\"), r'[^\\w\\s]', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1d1e5a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|switchfoot httptw...|\n",
      "|is upset that he ...|\n",
      "|kenichan i dived ...|\n",
      "|my whole body fee...|\n",
      "|nationwideclass n...|\n",
      "|kwesidei not the ...|\n",
      "|         need a hug |\n",
      "|loltrish hey  lon...|\n",
      "|tatiana_k nope th...|\n",
      "|twittera que me m...|\n",
      "|spring break in p...|\n",
      "|i just repierced ...|\n",
      "|caregiving i coul...|\n",
      "|octolinz16 it it ...|\n",
      "|smarrison i would...|\n",
      "|iamjazzyfizzle i ...|\n",
      "|hollis death scen...|\n",
      "|about to file taxes |\n",
      "|lettya ahh ive al...|\n",
      "|fakerpattypattz o...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a585c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Stop Words\n",
    "#Load stop word once and broadcast it to all worker nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1d1dc544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop  = stopwords.words('english')\n",
    "broadcasted_stopwords = spark.sparkContext.broadcast(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e3d08275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a funcion to remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f9ba5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bbff2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8548d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_udf = udf(remove_stopwords, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1f3c218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8b9af6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = Tweets.withColumn(\"Text\", remove_stopwords_udf(Tweets[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5d5c456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|switchfoot httptw...|\n",
      "|upset cant update...|\n",
      "|kenichan dived ma...|\n",
      "|whole body feels ...|\n",
      "|nationwideclass b...|\n",
      "| kwesidei whole crew|\n",
      "|            need hug|\n",
      "|loltrish hey long...|\n",
      "|tatiana_k nope didnt|\n",
      "|  twittera que muera|\n",
      "|spring break plai...|\n",
      "|      repierced ears|\n",
      "|caregiving couldn...|\n",
      "|octolinz16 counts...|\n",
      "|smarrison wouldve...|\n",
      "|iamjazzyfizzle wi...|\n",
      "|hollis death scen...|\n",
      "|          file taxes|\n",
      "|lettya ahh ive al...|\n",
      "|fakerpattypattz o...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tweets.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21587b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cd2155dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "#=                          T O K E N I Z A T I O N                                      =\n",
    "#= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650703c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdde94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d758ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14644c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Procesising in panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.withColumn(\"Text\", lower(df[\"text\"]))\n",
    "#df = df.withColumn(\"Text\", regexp_replace(df[\"text\"], \"[^a-z0-9\\\\s]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42db868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4de8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1276b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c2580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ff6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680cd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ff69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Text\", lower(df[\"text\"]))\n",
    "df = df.withColumn(\"Text\", regexp_replace(df[\"text\"], \"[^a-z0-9\\\\s]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd8298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
